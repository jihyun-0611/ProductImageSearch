{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\ahi06\\miniconda3\\envs\\pytorch_env\\lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import glob\n",
    "import os.path as osp\n",
    "import random\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "\n",
    "import torch\n",
    "from torchvision import transforms\n",
    "import torch.utils.data as data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def make_data_path(root):\n",
    "    \"\"\"\n",
    "    make data path list\n",
    "\n",
    "    :return:\n",
    "    path_list: list\n",
    "    \"\"\"\n",
    "    root_path = root + 'images\\\\'\n",
    "    ids_labels = np.load(root + 'id_label.npy', allow_pickle=True)\n",
    "\n",
    "    path_list = []\n",
    "    # glob -> load file path of sub directory\n",
    "    for id in ids_labels[:,0]:\n",
    "        path_list.append(root_path + str(id) + '.jpg')\n",
    "\n",
    "    return path_list, list(ids_labels)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ImageTransform:\n",
    "    \"\"\"\n",
    "    image pre-processing: resize image, normalization RGB value\n",
    "    version : train, validation\n",
    "    * train_version : image data augmentation\n",
    "\n",
    "    Attributes\n",
    "    ----------\n",
    "    resize: int\n",
    "    mean : (R, G, B)\n",
    "    std : (R, G, B)\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, resize, mean, std):\n",
    "        self.data_transform = {\n",
    "            'train': transforms.Compose([\n",
    "                transforms.RandomResizedCrop(resize, scale=(0.5, 1.0)),\n",
    "                transforms.RandomHorizontalFlip(),\n",
    "                transforms.ToTensor(),\n",
    "                transforms.Normalize(mean, std)\n",
    "            ]),\n",
    "            'val': transforms.Compose([\n",
    "                transforms.Resize(resize),\n",
    "                transforms.CenterCrop(resize),\n",
    "                transforms.ToTensor(),\n",
    "                transforms.Normalize(mean, std)\n",
    "            ])\n",
    "        }\n",
    "\n",
    "    def __call__(self, img, phase='train'):\n",
    "        \"\"\"\n",
    "        :param img: image data\n",
    "        :param phase: 'train' or 'val' -> specify dataset mode\n",
    "        :return: self.data_transform\n",
    "        \"\"\"\n",
    "        return self.data_transform[phase](img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ProductDataset(data.Dataset):\n",
    "    \"\"\"\n",
    "    ant, bee image Dataset class. Dataset class 상속\n",
    "\n",
    "    Attributes\n",
    "    ----------\n",
    "    file_list : list\n",
    "        -> file path list\n",
    "    transform : object\n",
    "        -> data pre-processing instance\n",
    "    phase : 'train' or 'val'\n",
    "\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, file_list, transform=None, phase=\"train\"):\n",
    "        self.file_list, self.labels = file_list\n",
    "        self.transform = transform\n",
    "        self.phase = phase\n",
    "\n",
    "    def __len__(self):\n",
    "        \"\"\"return length of images\"\"\"\n",
    "        return len(self.file_list)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        \"\"\"\n",
    "        get the Tensor and label of pre-processed image\n",
    "        :param idx: index of data\n",
    "        :return:\n",
    "        \"\"\"\n",
    "\n",
    "        # load image\n",
    "        img_path = self.file_list[idx]\n",
    "        img_id, label = self.labels[idx]\n",
    "        img = Image.open(img_path)\n",
    "\n",
    "        # pre-processing image data\n",
    "        img_transformed = self.transform(img, self.phase)  # torch.Size([3, 224, 224])\n",
    "\n",
    "        return img_transformed, label\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([32, 3, 224, 224])\n",
      "('Tshirts', 'Handbags', 'Wallets', 'Wallets', 'Clutches', 'Handbags', 'Tshirts', 'Sports Shoes', 'Kurta Sets', 'Sports Shoes', 'Watches', 'Nightdress', 'Kurtas', 'Shirts', 'Tshirts', 'Shirts', 'Tshirts', 'Tshirts', 'Dresses', 'Tshirts', 'Kurtas', 'Perfume and Body Mist', 'Tshirts', 'Flats', 'Tshirts', 'Casual Shoes', 'Ties', 'Sports Shoes', 'Tshirts', 'Bra', 'Tshirts', 'Handbags')\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv()\n",
    "root = os.environ.get(\"ROOT\")\n",
    "\n",
    "train_list = make_data_path(root)\n",
    "val_list = make_data_path(root)\n",
    "size = 224\n",
    "mean = (0.485, 0.456, 0.406)\n",
    "std = (0.229, 0.224, 0.225)\n",
    "train_dataset = ProductDataset(file_list=train_list, transform=ImageTransform(size, mean, std), phase='train')\n",
    "val_dataset = ProductDataset(file_list=val_list, transform=ImageTransform(size, mean, std))\n",
    "# batch size\n",
    "batch_size = 32\n",
    "# data loader\n",
    "train_dataLoader = torch.utils.data.DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "val_dataLoader = torch.utils.data.DataLoader(val_dataset, batch_size=batch_size, shuffle=False)\n",
    "dataLoaders_dict = {\"train\": train_dataLoader, \"val\": val_dataLoader}\n",
    "\n",
    "# test\n",
    "batch_iterator = iter(dataLoaders_dict[\"train\"]) # 반복이 가능한 iterator로 변환\n",
    "inputs, labels = next(batch_iterator) # 첫번쨰 요소 추출\n",
    "print(inputs.size())\n",
    "print(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
